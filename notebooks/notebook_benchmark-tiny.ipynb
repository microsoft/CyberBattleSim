{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-african",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:05.271223Z",
     "iopub.status.busy": "2024-08-04T03:19:05.270621Z",
     "iopub.status.idle": "2024-08-04T03:19:05.283291Z",
     "shell.execute_reply": "2024-08-04T03:19:05.282271Z"
    },
    "papermill": {
     "duration": 0.018961,
     "end_time": "2024-08-04T03:19:05.285194",
     "exception": false,
     "start_time": "2024-08-04T03:19:05.266233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "\"\"\"Benchmark all the baseline agents\n",
    "on a given CyberBattleSim environment and compare\n",
    "them to the dumb 'random agent' baseline.\n",
    "\n",
    "NOTE: You can run this `.py`-notebook directly from VSCode.\n",
    "You can also generate a traditional Jupyter Notebook\n",
    "using the VSCode command `Export Currenty Python File As Jupyter Notebook`.\n",
    "\"\"\"\n",
    "\n",
    "# pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-stretch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:05.292599Z",
     "iopub.status.busy": "2024-08-04T03:19:05.291889Z",
     "iopub.status.idle": "2024-08-04T03:19:06.867255Z",
     "shell.execute_reply": "2024-08-04T03:19:06.866358Z"
    },
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": 1.580666,
     "end_time": "2024-08-04T03:19:06.869131",
     "exception": false,
     "start_time": "2024-08-04T03:19:05.288465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import gym\n",
    "import cyberbattle.agents.baseline.learner as learner\n",
    "import cyberbattle.agents.baseline.plotting as p\n",
    "import cyberbattle.agents.baseline.agent_wrapper as w\n",
    "import cyberbattle.agents.baseline.agent_randomcredlookup as rca\n",
    "import cyberbattle.agents.baseline.agent_tabularqlearning as tqa\n",
    "import cyberbattle.agents.baseline.agent_dql as dqla\n",
    "from cyberbattle.agents.baseline.agent_wrapper import Verbosity\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR, format=\"%(levelname)s: %(message)s\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-slave",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:06.876550Z",
     "iopub.status.busy": "2024-08-04T03:19:06.876068Z",
     "iopub.status.idle": "2024-08-04T03:19:06.881904Z",
     "shell.execute_reply": "2024-08-04T03:19:06.880861Z"
    },
    "papermill": {
     "duration": 0.010536,
     "end_time": "2024-08-04T03:19:06.883486",
     "exception": false,
     "start_time": "2024-08-04T03:19:06.872950",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Papermill notebook parameters\n",
    "gymid = \"CyberBattleTiny-v0\"\n",
    "iteration_count = 200\n",
    "training_episode_count = 10\n",
    "eval_episode_count = 10\n",
    "maximum_node_count = 5\n",
    "maximum_total_credentials = 3\n",
    "plots_dir = \"plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-gates",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:06.928672Z",
     "iopub.status.busy": "2024-08-04T03:19:06.928033Z",
     "iopub.status.idle": "2024-08-04T03:19:06.936107Z",
     "shell.execute_reply": "2024-08-04T03:19:06.935259Z"
    },
    "papermill": {
     "duration": 0.012552,
     "end_time": "2024-08-04T03:19:06.937520",
     "exception": false,
     "start_time": "2024-08-04T03:19:06.924968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Load the Gym environment\n",
    "_gym_env = gym.make(gymid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca884a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "from cyberbattle._env.cyberbattle_env import CyberBattleEnv\n",
    "\n",
    "gym_env = cast(CyberBattleEnv, _gym_env.unwrapped)\n",
    "assert isinstance(gym_env, CyberBattleEnv), f\"Expected CyberBattleEnv, got {type(gym_env)}\"\n",
    "\n",
    "ep = w.EnvironmentBounds.of_identifiers(maximum_node_count=maximum_node_count, maximum_total_credentials=maximum_total_credentials, identifiers=gym_env.identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-entry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:06.943050Z",
     "iopub.status.busy": "2024-08-04T03:19:06.942596Z",
     "iopub.status.idle": "2024-08-04T03:19:06.949756Z",
     "shell.execute_reply": "2024-08-04T03:19:06.948817Z"
    },
    "papermill": {
     "duration": 0.011562,
     "end_time": "2024-08-04T03:19:06.951279",
     "exception": false,
     "start_time": "2024-08-04T03:19:06.939717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "debugging = False\n",
    "if debugging:\n",
    "    print(f\"port_count = {ep.port_count}, property_count = {ep.property_count}\")\n",
    "\n",
    "    gym_env.environment\n",
    "    # training_env.environment.plot_environment_graph()\n",
    "    gym_env.environment.network.nodes\n",
    "    gym_env.action_space\n",
    "    gym_env.action_space.sample()\n",
    "    gym_env.observation_space.sample()\n",
    "    o0 = gym_env.reset()\n",
    "    o_test, r, d, t, i = gym_env.step(gym_env.sample_valid_action())\n",
    "    o0, _ = gym_env.reset()\n",
    "\n",
    "    o0.keys()\n",
    "\n",
    "    fe_example = w.RavelEncoding(ep, [w.Feature_active_node_properties(ep), w.Feature_discovered_node_count(ep)])\n",
    "    a = w.StateAugmentation(o0)\n",
    "    w.Feature_discovered_ports(ep).get(a)\n",
    "    fe_example.encode_at(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-cowboy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:06.957602Z",
     "iopub.status.busy": "2024-08-04T03:19:06.956799Z",
     "iopub.status.idle": "2024-08-04T03:19:08.348986Z",
     "shell.execute_reply": "2024-08-04T03:19:08.348056Z"
    },
    "papermill": {
     "duration": 1.397021,
     "end_time": "2024-08-04T03:19:08.350599",
     "exception": false,
     "start_time": "2024-08-04T03:19:06.953578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate a random agent that opportunistically exploits\n",
    "# credentials gathere in its local cache\n",
    "credlookup_run = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=rca.CredentialCacheExploiter(),\n",
    "    episode_count=10,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    render=False,\n",
    "    epsilon_exponential_decay=10000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"Credential lookups (Ïµ-greedy)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-induction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:08.366523Z",
     "iopub.status.busy": "2024-08-04T03:19:08.366094Z",
     "iopub.status.idle": "2024-08-04T03:19:10.838836Z",
     "shell.execute_reply": "2024-08-04T03:19:10.837985Z"
    },
    "papermill": {
     "duration": 2.482136,
     "end_time": "2024-08-04T03:19:10.840304",
     "exception": false,
     "start_time": "2024-08-04T03:19:08.358168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate a Tabular Q-learning agent\n",
    "tabularq_run = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=tqa.QTabularLearner(ep, gamma=0.015, learning_rate=0.01, exploit_percentile=100),\n",
    "    episode_count=training_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.01,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"Tabular Q-learning\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-fraction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:10.868789Z",
     "iopub.status.busy": "2024-08-04T03:19:10.868130Z",
     "iopub.status.idle": "2024-08-04T03:19:13.127747Z",
     "shell.execute_reply": "2024-08-04T03:19:13.126803Z"
    },
    "papermill": {
     "duration": 2.275446,
     "end_time": "2024-08-04T03:19:13.129289",
     "exception": false,
     "start_time": "2024-08-04T03:19:10.853843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate an agent that exploits the Q-table learnt above\n",
    "tabularq_exploit_run = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=tqa.QTabularLearner(ep, trained=tabularq_run[\"learner\"], gamma=0.0, learning_rate=0.0, exploit_percentile=90),\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.0,\n",
    "    render=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"Exploiting Q-matrix\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-allocation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:19:13.166400Z",
     "iopub.status.busy": "2024-08-04T03:19:13.165823Z",
     "iopub.status.idle": "2024-08-04T03:20:11.158810Z",
     "shell.execute_reply": "2024-08-04T03:20:11.157626Z"
    },
    "papermill": {
     "duration": 58.013348,
     "end_time": "2024-08-04T03:20:11.160664",
     "exception": false,
     "start_time": "2024-08-04T03:19:13.147316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the Deep Q-learning agent\n",
    "dql_run = learner.epsilon_greedy_search(\n",
    "    cyberbattle_gym_env=gym_env,\n",
    "    environment_properties=ep,\n",
    "    learner=dqla.DeepQLearnerPolicy(\n",
    "        ep=ep,\n",
    "        gamma=0.015,\n",
    "        replay_memory_size=10000,\n",
    "        target_update=10,\n",
    "        batch_size=512,\n",
    "        # torch default learning rate is 1e-2\n",
    "        # a large value helps converge in less episodes\n",
    "        learning_rate=0.01,\n",
    "    ),\n",
    "    episode_count=training_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.90,\n",
    "    epsilon_exponential_decay=5000,\n",
    "    epsilon_minimum=0.10,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"DQL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-surveillance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:20:11.249983Z",
     "iopub.status.busy": "2024-08-04T03:20:11.249363Z",
     "iopub.status.idle": "2024-08-04T03:21:42.507033Z",
     "shell.execute_reply": "2024-08-04T03:21:42.505688Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 91.303928,
     "end_time": "2024-08-04T03:21:42.509109",
     "exception": false,
     "start_time": "2024-08-04T03:20:11.205181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate an agent that exploits the Q-function learnt above\n",
    "dql_exploit_run = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=dql_run[\"learner\"],\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=0.0,\n",
    "    epsilon_minimum=0.00,\n",
    "    render=False,\n",
    "    plot_episodes_length=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    title=\"Exploiting DQL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-sleeping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:21:42.664542Z",
     "iopub.status.busy": "2024-08-04T03:21:42.663688Z",
     "iopub.status.idle": "2024-08-04T03:21:44.264995Z",
     "shell.execute_reply": "2024-08-04T03:21:44.263867Z"
    },
    "papermill": {
     "duration": 1.681428,
     "end_time": "2024-08-04T03:21:44.266330",
     "exception": false,
     "start_time": "2024-08-04T03:21:42.584902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the random agent\n",
    "random_run = learner.epsilon_greedy_search(\n",
    "    gym_env,\n",
    "    ep,\n",
    "    learner=learner.RandomPolicy(),\n",
    "    episode_count=eval_episode_count,\n",
    "    iteration_count=iteration_count,\n",
    "    epsilon=1.0,  # purely random\n",
    "    render=False,\n",
    "    verbosity=Verbosity.Quiet,\n",
    "    plot_episodes_length=False,\n",
    "    title=\"Random search\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-sperm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:21:44.438348Z",
     "iopub.status.busy": "2024-08-04T03:21:44.437914Z",
     "iopub.status.idle": "2024-08-04T03:21:44.736933Z",
     "shell.execute_reply": "2024-08-04T03:21:44.735977Z"
    },
    "papermill": {
     "duration": 0.3913,
     "end_time": "2024-08-04T03:21:44.738308",
     "exception": false,
     "start_time": "2024-08-04T03:21:44.347008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare and plot results for all the agents\n",
    "all_runs = [random_run, credlookup_run, tabularq_run, tabularq_exploit_run, dql_run, dql_exploit_run]\n",
    "\n",
    "# Plot averaged cumulative rewards for DQL vs Random vs DQL-Exploit\n",
    "themodel = dqla.CyberBattleStateActionModel(ep)\n",
    "p.plot_averaged_cummulative_rewards(\n",
    "    all_runs=all_runs,\n",
    "    title=f\"Benchmark -- max_nodes={ep.maximum_node_count}, episodes={eval_episode_count},\\n\"\n",
    "    f\"State: {[f.name() for f in themodel.state_space.feature_selection]} \"\n",
    "    f\"({len(themodel.state_space.feature_selection)}\\n\"\n",
    "    f\"Action: abstract_action ({themodel.action_space.flat_size()})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-thanks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:21:44.931315Z",
     "iopub.status.busy": "2024-08-04T03:21:44.930734Z",
     "iopub.status.idle": "2024-08-04T03:21:45.303426Z",
     "shell.execute_reply": "2024-08-04T03:21:45.302554Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.457632,
     "end_time": "2024-08-04T03:21:45.305027",
     "exception": false,
     "start_time": "2024-08-04T03:21:44.847395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contenders = [credlookup_run, tabularq_run, dql_run, dql_exploit_run]\n",
    "p.plot_episodes_length(contenders)\n",
    "p.plot_averaged_cummulative_rewards(title=f\"Agent Benchmark top contenders\\n\" f\"max_nodes:{ep.maximum_node_count}\\n\", all_runs=contenders, show=False)\n",
    "\n",
    "plt.savefig(os.path.join(plots_dir, \"benchmark-tiny-finalplot.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-buyer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:21:45.476856Z",
     "iopub.status.busy": "2024-08-04T03:21:45.476230Z",
     "iopub.status.idle": "2024-08-04T03:21:46.389750Z",
     "shell.execute_reply": "2024-08-04T03:21:46.388863Z"
    },
    "papermill": {
     "duration": 1.001389,
     "end_time": "2024-08-04T03:21:46.391216",
     "exception": false,
     "start_time": "2024-08-04T03:21:45.389827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot cumulative rewards for all episodes\n",
    "for r in contenders:\n",
    "    p.plot_all_episodes(r)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "cell_metadata_json": true
  },
  "kernelspec": {
   "display_name": "cybersim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 162.796147,
   "end_time": "2024-08-04T03:21:47.100191",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/notebook_benchmark-tiny.ipynb",
   "output_path": "notebooks/output/notebook_benchmark-tiny.ipynb",
   "parameters": {
    "eval_episode_count": 10,
    "gymid": "CyberBattleTiny-v0",
    "iteration_count": 200,
    "maximum_node_count": 5,
    "maximum_total_credentials": 3,
    "training_episode_count": 10
   },
   "start_time": "2024-08-04T03:19:04.304044",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
